# MediaPipe graph to process hand gestures (mkel).

type: "GestureProcessorSubgraph"

# CPU image. (ImageFrame)
input_stream: "IMAGE:input_image"

# Collection of detected/predicted hands, each represented as a list of
# landmarks. (std::vector<NormalizedLandmarkList>)
input_stream: "LANDMARKS:multi_hand_landmarks"

# Handedness of the detected hand (i.e. is hand left or right).
# (std::vector<ClassificationList>)
input_stream: "HANDEDNESS:multi_handedness"

# Regions of interest calculated based on palm detections.
# (std::vector<NormalizedRect>)
input_stream: "NORM_RECTS:0:multi_palm_rects"

# Regions of interest calculated based on landmarks.
# (std::vector<NormalizedRect>)
input_stream: "NORM_RECTS:1:multi_hand_rects"

# Detected palms. (std::vector<Detection>)
input_stream: "DETECTIONS:palm_detections"

# Updated CPU image. (ImageFrame)
output_stream: "IMAGE:output_image"

# Converts detections to drawing primitives for annotation overlay.
node {
  calculator: "GestureRecognizerCalculator"
  input_stream: "MULTI_NORM_LANDMARKS:multi_hand_landmarks"
  input_stream: "IMAGE:input_image"
  input_stream: "HANDEDNESS:multi_handedness"

  #output_stream: "RENDER_DATA:detection_render_data"
}
